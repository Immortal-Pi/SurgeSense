{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error,r2_score,mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from urllib.parse import urlparse\n",
    "import mlflow \n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from SurgeSense.constants import * \n",
    "from SurgeSense.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\pythonProjects\\\\SurgeSense\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\pythonProjects\\\\SurgeSense'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class HyperOptParamsGradientBoosting:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path \n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    n_estimators: list \n",
    "    max_depth: list \n",
    "    learning_rate: str \n",
    "    target_column: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration \n",
    "class HyperOptParamsConfigManagerGradientBoosting:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_file_path=CONFIG_FILE_PATH,\n",
    "            params_file_path=PARAMS_FILE_PATH,\n",
    "            schema_file_path=SCHEMA_FILE_PATH,\n",
    "            ):\n",
    "        self.config=read_yaml(config_file_path)\n",
    "        self.params=read_yaml(params_file_path)\n",
    "        self.schema=read_yaml(schema_file_path)\n",
    "    \n",
    "    def get_hyperopt_config(self)->HyperOptParamsGradientBoosting:\n",
    "        config=self.config.model_trainer \n",
    "        params=self.params.Hyperopt_params.GRADIENT_BOOSTING\n",
    "        schema=self.schema.TARGET_COLUMN\n",
    "\n",
    "        hypoeropt_config=HyperOptParamsGradientBoosting(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            n_estimators=params.n_estimators,\n",
    "            max_depth=params.max_depth,\n",
    "            learning_rate=params.learning_rate,\n",
    "            target_column=schema.name\n",
    "        )\n",
    "        return hypoeropt_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# components\n",
    "from hyperopt import STATUS_OK, hp, fmin, tpe, Trials\n",
    "import dagshub\n",
    "from functools import partial \n",
    "import mlflow\n",
    "import pandas as pd \n",
    "import os \n",
    "from SurgeSense import logger\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "class hyperOptTraining:\n",
    "    def __init__(self,config=HyperOptParamsGradientBoosting):\n",
    "          self.config=config\n",
    "\n",
    "\n",
    "    def evaluation_metrics(actual,pred):\n",
    "        rmse=np.sqrt(mean_squared_error(actual,pred))\n",
    "        mae=mean_absolute_error(actual,pred)\n",
    "        r2=r2_score(actual,pred)\n",
    "        return rmse, mae, r2 \n",
    "\n",
    "\n",
    "    def create_pipeline(self):\n",
    "        \n",
    "        categorical_columns=['cab_type','destination','source','name']\n",
    "        numerical_columns=['distance','surge_multiplier','temp','clouds','pressure','rain','humidity','wind','day','hour','month']\n",
    "\n",
    "        numerical_preprocessor=Pipeline(\n",
    "            steps=[\n",
    "                ('imputation_menu',SimpleImputer(missing_values=np.nan,strategy='median')),\n",
    "                ('scalar',StandardScaler())\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        categorical_preprocessor=Pipeline(\n",
    "            steps=[\n",
    "                ('imputation_constant',SimpleImputer(strategy='most_frequent')),\n",
    "                ('encode',OneHotEncoder(handle_unknown='ignore'))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        preprocessor=ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('categorical_columns',categorical_preprocessor,categorical_columns),\n",
    "                ('numerical_columns',numerical_preprocessor,numerical_columns)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "        pipe=Pipeline(\n",
    "            steps=[\n",
    "                ('preprocessor',preprocessor),\n",
    "                ('model', GradientBoostingRegressor())\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "\n",
    "        return pipe\n",
    "\n",
    "    def evaluation_metrics(self,actual,pred):\n",
    "        rmse=np.sqrt(mean_squared_error(actual,pred))\n",
    "        mae=mean_absolute_error(actual,pred)\n",
    "        r2=r2_score(actual,pred)\n",
    "        return rmse, mae, r2\n",
    "\n",
    "    def objective(self,params,xtrain,ytrain,xtest,ytest):\n",
    "        with mlflow.start_run():\n",
    "            mlflow.set_tag('model','XGBoostRegressor')\n",
    "\n",
    "            pipe=self.create_pipeline()\n",
    "            model=pipe.set_params(**params)\n",
    "            model.fit(xtrain,ytrain)\n",
    "            ypred=model.predict(xtest)\n",
    "            mlflow.log_params(model.get_params())\n",
    "            rmse,mae,r2=self.evaluation_metrics(ytest,ypred)\n",
    "            mlflow.log_metrics({'rmse':rmse,'mse': mae, 'r2':r2})\n",
    "        return {'loss':rmse, 'status':STATUS_OK, 'model':model}\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        train_data=pd.read_csv(self.config.train_data_path)\n",
    "        test_data=pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "        xtrain=train_data.drop([self.config.target_column],axis=1)\n",
    "        xtest=test_data.drop([self.config.target_column],axis=1)\n",
    "        ytrain=train_data[[self.config.target_column]]\n",
    "        ytest=test_data[[self.config.target_column]]\n",
    "\n",
    "        search_space={\n",
    "            'model__n_estimators':hp.uniformint('n_estimators',self.config.n_estimators[0],self.config.n_estimators[1]),\n",
    "            'model__max_depth':hp.uniformint('max_depth',self.config.max_depth[0],self.config.max_depth[1]),\n",
    "            'model__learning_rate':hp.uniform('learning_rate',self.config.learning_rate[0],self.config.learning_rate[1])\n",
    "        }\n",
    "        dagshub.init(repo_owner='Immortal-Pi',repo_name='SurgeSense',mlflow=True)\n",
    "        experiment_name='hyperopt_test_gradient_boosting'\n",
    "        existing_experiment=mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "        if existing_experiment is None:\n",
    "                experiment_id = mlflow.create_experiment(name=experiment_name,artifact_location='hyperopt-test')\n",
    "        else:\n",
    "            experiment_id = existing_experiment.experiment_id\n",
    "        mlflow.set_experiment(experiment_id=experiment_id) \n",
    "\n",
    "        trials=Trials()\n",
    "        best_results=fmin(\n",
    "            fn=partial(\n",
    "                self.objective,\n",
    "                xtrain=xtrain[:1000],\n",
    "                ytrain=ytrain[:1000],\n",
    "                xtest=xtest[:1000],\n",
    "                ytest=ytest[:1000]\n",
    "            ),\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10, # change to config\n",
    "            trials=trials\n",
    "        )\n",
    "        return best_results,trials\n",
    "\n",
    "    def register_best_model(self,best_results,trials):\n",
    "        best_index=np.argmin([trial['result']['loss'] for trial in trials.trials])\n",
    "        best_model=trials.trials[best_index]['result']['model']\n",
    "\n",
    "        with mlflow.start_run() as run:\n",
    "            mlflow.sklearn.log_model(best_model,artifact_path='model')\n",
    "            mlflow.log_params(trials.trials[best_index]['misc']['vals'])\n",
    "            model_uri=f'runs:/{run.info.run_id}/best_model'\n",
    "            mlflow.register_model(model_uri=model_uri,name='best_model')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 12:03:21,168: INFO :common : yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-03-24 12:03:21,173: INFO :common : yaml file: params.yaml loaded successfully]\n",
      "[2025-03-24 12:03:21,178: INFO :common : yaml file: schema.yaml loaded successfully]\n",
      "[2025-03-24 12:03:23,897: INFO :_client : HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Immortal-Pi\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Immortal-Pi\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 12:03:23,907: INFO :helpers : Accessing as Immortal-Pi]\n",
      "[2025-03-24 12:03:24,109: INFO :_client : HTTP Request: GET https://dagshub.com/api/v1/repos/Immortal-Pi/SurgeSense \"HTTP/1.1 200 OK\"]\n",
      "[2025-03-24 12:03:24,227: INFO :_client : HTTP Request: GET https://dagshub.com/api/v1/user \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Immortal-Pi/SurgeSense\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Immortal-Pi/SurgeSense\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 12:03:24,232: INFO :helpers : Initialized MLflow to track repo \"Immortal-Pi/SurgeSense\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Immortal-Pi/SurgeSense initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Immortal-Pi/SurgeSense initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-24 12:03:24,235: INFO :helpers : Repository Immortal-Pi/SurgeSense initialized!]\n",
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?][2025-03-24 12:03:24,585: INFO :tpe : build_posterior_wrapper took 0.001616 seconds]\n",
      "[2025-03-24 12:03:24,587: INFO :tpe : TPE using 0 trials]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProjects\\SurgeSense\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:672: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run melodic-donkey-778 at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4/runs/243488ca18884cd4a37e4fbef09cf4fb\n",
      "\n",
      "🧪 View experiment at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4\n",
      "\n",
      " 10%|█         | 1/10 [00:11<01:43, 11.54s/trial, best loss: 2.9903814644606768][2025-03-24 12:03:36,127: INFO :tpe : build_posterior_wrapper took 0.001000 seconds]\n",
      "[2025-03-24 12:03:36,127: INFO :tpe : TPE using 1/1 trials with best loss 2.990381]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProjects\\SurgeSense\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:672: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run brawny-gnu-531 at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4/runs/fdcdd2a6f193402f890771d7745fc7ad\n",
      "\n",
      "🧪 View experiment at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4\n",
      "\n",
      " 20%|██        | 2/10 [00:27<01:53, 14.19s/trial, best loss: 2.965866192689635] [2025-03-24 12:03:52,176: INFO :tpe : build_posterior_wrapper took 0.005964 seconds]\n",
      "[2025-03-24 12:03:52,179: INFO :tpe : TPE using 2/2 trials with best loss 2.965866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProjects\\SurgeSense\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:672: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run treasured-carp-15 at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4/runs/37b23673363649958779d4ce211c0caf\n",
      "\n",
      "🧪 View experiment at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4\n",
      "\n",
      " 30%|███       | 3/10 [00:43<01:44, 14.99s/trial, best loss: 2.965866192689635][2025-03-24 12:04:08,122: INFO :tpe : build_posterior_wrapper took 0.000982 seconds]\n",
      "[2025-03-24 12:04:08,124: INFO :tpe : TPE using 3/3 trials with best loss 2.965866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProjects\\SurgeSense\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:672: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run industrious-bass-95 at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4/runs/2cd12d5bc20c437881ee5431fd893fb6\n",
      "\n",
      "🧪 View experiment at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4\n",
      "\n",
      " 40%|████      | 4/10 [01:02<01:39, 16.58s/trial, best loss: 2.965866192689635][2025-03-24 12:04:27,130: INFO :tpe : build_posterior_wrapper took 0.001009 seconds]\n",
      "[2025-03-24 12:04:27,131: INFO :tpe : TPE using 4/4 trials with best loss 2.965866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProjects\\SurgeSense\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:672: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run incongruous-bear-930 at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4/runs/4c58913ccd9b4c01bb66a0fc4f815887\n",
      "\n",
      "🧪 View experiment at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4\n",
      "\n",
      " 50%|█████     | 5/10 [01:19<01:23, 16.74s/trial, best loss: 2.965866192689635][2025-03-24 12:04:44,159: INFO :tpe : build_posterior_wrapper took 0.000994 seconds]\n",
      "[2025-03-24 12:04:44,160: INFO :tpe : TPE using 5/5 trials with best loss 2.965866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProjects\\SurgeSense\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:672: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run dapper-gnat-390 at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4/runs/5ae8c6d2a56949a1bc46880bb2610222\n",
      "\n",
      "🧪 View experiment at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4\n",
      "\n",
      " 60%|██████    | 6/10 [01:37<01:08, 17.16s/trial, best loss: 2.965866192689635][2025-03-24 12:05:02,122: INFO :tpe : build_posterior_wrapper took 0.000908 seconds]\n",
      "[2025-03-24 12:05:02,122: INFO :tpe : TPE using 6/6 trials with best loss 2.965866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProjects\\SurgeSense\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:672: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run salty-squirrel-744 at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4/runs/87d5f70ea07443bfa0dfee4c318f7b1a\n",
      "\n",
      "🧪 View experiment at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4\n",
      "\n",
      " 70%|███████   | 7/10 [01:57<00:54, 18.10s/trial, best loss: 2.965866192689635][2025-03-24 12:05:22,154: INFO :tpe : build_posterior_wrapper took 0.001140 seconds]\n",
      "[2025-03-24 12:05:22,155: INFO :tpe : TPE using 7/7 trials with best loss 2.965866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProjects\\SurgeSense\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:672: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run kindly-koi-864 at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4/runs/2ec8ca60b36f4f719f9de35609557889\n",
      "\n",
      "🧪 View experiment at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4\n",
      "\n",
      " 80%|████████  | 8/10 [02:13<00:34, 17.42s/trial, best loss: 2.965866192689635][2025-03-24 12:05:38,125: INFO :tpe : build_posterior_wrapper took 0.000999 seconds]\n",
      "[2025-03-24 12:05:38,126: INFO :tpe : TPE using 8/8 trials with best loss 2.965866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProjects\\SurgeSense\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:672: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run bald-squid-533 at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4/runs/2aa19a2278c44ac291b9f1d9a1f2d890\n",
      "\n",
      "🧪 View experiment at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4\n",
      "\n",
      " 90%|█████████ | 9/10 [02:32<00:17, 17.92s/trial, best loss: 2.965866192689635][2025-03-24 12:05:57,156: INFO :tpe : build_posterior_wrapper took 0.002056 seconds]\n",
      "[2025-03-24 12:05:57,158: INFO :tpe : TPE using 9/9 trials with best loss 2.965866]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonProjects\\SurgeSense\\venv\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:672: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run classy-shrimp-548 at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4/runs/f4828a616eb5464da1fad1911818ee18\n",
      "\n",
      "🧪 View experiment at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4\n",
      "\n",
      "100%|██████████| 10/10 [02:44<00:00, 16.46s/trial, best loss: 2.965866192689635]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/24 12:06:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'best_model' already exists. Creating a new version of this model...\n",
      "2025/03/24 12:06:26 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: best_model, version 9\n",
      "Created version '9' of model 'best_model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run dapper-auk-698 at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4/runs/65dcdc352c3d46b5870474b62a312c92\n",
      "🧪 View experiment at: https://dagshub.com/Immortal-Pi/SurgeSense.mlflow/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "# pipeline \n",
    "try: \n",
    "    config=HyperOptParamsConfigManagerGradientBoosting()\n",
    "    hyperopt_config=config.get_hyperopt_config()\n",
    "    hyperopt_config_training=hyperOptTraining(config=hyperopt_config)\n",
    "    best_results,trails=hyperopt_config_training.train()\n",
    "    hyperopt_config_training.register_best_model(best_results,trails)\n",
    "except Exception as e:\n",
    "    raise e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
