{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error,r2_score,mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from urllib.parse import urlparse\n",
    "import mlflow \n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from SurgeSense.constants import * \n",
    "from SurgeSense.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\pythonProjects\\\\SurgeSense\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\pythonProjects\\\\SurgeSense'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(actual,pred):\n",
    "    rmse=np.sqrt(mean_squared_error(actual,pred))\n",
    "    mae=mean_absolute_error(actual,pred)\n",
    "    r2=r2_score(actual,pred)\n",
    "    return rmse, mae, r2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-23 21:12:05,678: INFO :common : yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-03-23 21:12:05,692: INFO :common : yaml file: params.yaml loaded successfully]\n"
     ]
    }
   ],
   "source": [
    "config=read_yaml(CONFIG_FILE_PATH)\n",
    "params=read_yaml(PARAMS_FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class HyperOptParams:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path \n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    n_estimators: list \n",
    "    max_depth: list \n",
    "    learning_rate: str \n",
    "    target_column: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration \n",
    "class HyperOptParamsConfigManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_file_path=CONFIG_FILE_PATH,\n",
    "            params_file_path=PARAMS_FILE_PATH,\n",
    "            schema_file_path=SCHEMA_FILE_PATH,\n",
    "            ):\n",
    "        self.config=read_yaml(config_file_path)\n",
    "        self.params=read_yaml(params_file_path)\n",
    "        self.schema=read_yaml(schema_file_path)\n",
    "    \n",
    "    def get_hyperopt_config(self)->HyperOptParams:\n",
    "        config=self.config.model_trainer \n",
    "        params=self.params.Hyperopt_params.XGBoostRegressor\n",
    "        schema=self.schema.TARGET_COLUMN\n",
    "\n",
    "        hypoeropt_config=HyperOptParams(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            n_estimators=params.n_estimators,\n",
    "            max_depth=params.max_depth,\n",
    "            learning_rate=params.learning_rate,\n",
    "            target_column=schema.name\n",
    "        )\n",
    "        return hypoeropt_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# components\n",
    "from hyperopt import STATUS_OK, hp, fmin, tpe, Trials\n",
    "import dagshub\n",
    "from functools import partial \n",
    "import mlflow\n",
    "import pandas as pd \n",
    "import os \n",
    "from SurgeSense import logger\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "class hyperOptTraining:\n",
    "    def __init__(self,config=HyperOptParams):\n",
    "          self.config=config\n",
    "\n",
    "    def create_pipeline(self):\n",
    "        \n",
    "        categorical_columns=['cab_type','destination','source','name']\n",
    "        numerical_columns=['distance','surge_multiplier','temp','clouds','pressure','rain','humidity','wind','day','hour','month']\n",
    "\n",
    "        numerical_preprocessor=Pipeline(\n",
    "            steps=[\n",
    "                ('imputation_menu',SimpleImputer(missing_values=np.nan,strategy='median')),\n",
    "                ('scalar',StandardScaler())\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        categorical_preprocessor=Pipeline(\n",
    "            steps=[\n",
    "                ('imputation_constant',SimpleImputer(strategy='most_frequent')),\n",
    "                ('encode',OneHotEncoder(handle_unknown='ignore'))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        preprocessor=ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('categorical_columns',categorical_preprocessor,categorical_columns),\n",
    "                ('numerical_columns',numerical_preprocessor,numerical_columns)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        \n",
    "        pipe=Pipeline(\n",
    "            steps=[\n",
    "                ('preprocessor',preprocessor),\n",
    "                ('model', XGBRegressor())\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "\n",
    "        return pipe\n",
    "\n",
    "    def objective(self,params,xtrain,ytrain,xtest,ytest):\n",
    "        with mlflow.start_run():\n",
    "            mlflow.set_tag('model','XGBoostRegressor')\n",
    "\n",
    "            pipe=self.create_pipeline()\n",
    "            model=pipe.set_params(**params)\n",
    "            model.fit(xtrain,ytrain)\n",
    "            ypred=model.predict(xtest)\n",
    "            mlflow.log_params(model.get_params())\n",
    "            rmse,mae,r2=evaluation_metrics(ytest,ypred)\n",
    "            mlflow.log_metrics({'rmse':rmse,'mse': mae, 'r2':r2})\n",
    "        return {'loss':rmse, 'status':STATUS_OK, 'model':model}\n",
    "\n",
    "    def train(self):\n",
    "        train_data=pd.read_csv(self.config.train_data_path)\n",
    "        test_data=pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "        xtrain=train_data.drop([self.config.target_column],axis=1)\n",
    "        xtest=test_data.drop([self.config.target_column],axis=1)\n",
    "        ytrain=train_data[[self.config.target_column]]\n",
    "        ytest=test_data[[self.config.target_column]]\n",
    "\n",
    "        search_space={\n",
    "            'model__n_estimators':hp.uniformint('n_estimators',self.config.n_estimators[0],self.config.n_estimators[1]),\n",
    "            'model__max_depth':hp.uniformint('max_depth',self.config.max_depth[0],self.config.max_depth[1]),\n",
    "            'model__learning_rate':hp.uniform('learning_rate',self.config.learning_rate[0],self.config.learning_rate[1])\n",
    "        }\n",
    "        dagshub.init(repo_owner='Immortal-Pi',repo_name='SurgeSense',mlflow=True)\n",
    "        experiment_name='hyperopt_test_xgboostregressor_algorithm'\n",
    "        existing_experiment=mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "        if existing_experiment is None:\n",
    "                experiment_id = mlflow.create_experiment(name=experiment_name,artifact_location='hyperopt-test')\n",
    "        else:\n",
    "            experiment_id = existing_experiment.experiment_id\n",
    "        mlflow.set_experiment(experiment_id=experiment_id) \n",
    "\n",
    "        trials=Trials()\n",
    "        best_results=fmin(\n",
    "            fn=partial(\n",
    "                self.objective,\n",
    "                xtrain=xtrain,\n",
    "                ytrain=ytrain,\n",
    "                xtest=xtest,\n",
    "                ytest=ytest\n",
    "            ),\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10, # change to config\n",
    "            trials=trials\n",
    "        )\n",
    "        return best_results,trials\n",
    "\n",
    "    # def register_best_model(self,best_results,trials):\n",
    "    #     best_index=np.argmin([trial['result']['loss'] for trial in trials.trials])\n",
    "    #     best_model=trials.trials[best_index]['result']['loss']\n",
    "\n",
    "    #     with mlflow.start_run() as run:\n",
    "    #         mlflow.sklearn.log_model(sk_model=best_model,artifact_path='best_model')\n",
    "    #         mlflow.log_params(trials.trials[best_index]['mics']['vals'])\n",
    "    #         model_uri=f'runs:{run.info.run_id}/best_model'\n",
    "    #         mlflow.register_model(model_uri=model_uri,name='best_model')\n",
    "\n",
    "    def register_best_model(self,best_results,trials):\n",
    "        best_index=np.argmin([trial['result']['loss'] for trial in trials.trials])\n",
    "        best_trial=trials.trials[best_index]\n",
    "        best_model=best_trial['result']['model']\n",
    "        \n",
    "        param_vals = best_trial['misc']['vals']\n",
    "        flattened_params = {k: v[0] if isinstance(v, list) and v else None for k, v in param_vals.items()}\n",
    "\n",
    "        \n",
    "\n",
    "        with mlflow.start_run() as run:\n",
    "            mlflow.sklearn.log_model(sk_model=best_model,artifact_path='best_model')\n",
    "            # mlflow.log_params(trials.trials[best_index]['mics']['vals'])\n",
    "            mlflow.log_params(flattened_params)\n",
    "            model_uri=f'runs:{run.info.run_id}/best_model'\n",
    "            mlflow.register_model(model_uri=model_uri,name='best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-23 21:38:50,705: INFO :common : yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-03-23 21:38:50,710: INFO :common : yaml file: params.yaml loaded successfully]\n",
      "[2025-03-23 21:38:50,715: INFO :common : yaml file: schema.yaml loaded successfully]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     hyperopt_config_training\u001b[38;5;241m.\u001b[39mregister_best_model(best_results,trails)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \n",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     hyperopt_config_training\u001b[38;5;241m=\u001b[39mhyperOptTraining(config\u001b[38;5;241m=\u001b[39mhyperopt_config)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# best_results,trails=hyperopt_config_training.train()\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mhyperopt_config_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrails\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \n",
      "Cell \u001b[1;32mIn[14], line 126\u001b[0m, in \u001b[0;36mhyperOptTraining.register_best_model\u001b[1;34m(self, best_results, trials)\u001b[0m\n\u001b[0;32m    124\u001b[0m best_index\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmin([trial[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m trials\u001b[38;5;241m.\u001b[39mtrials])\n\u001b[0;32m    125\u001b[0m best_trial\u001b[38;5;241m=\u001b[39mtrials\u001b[38;5;241m.\u001b[39mtrials[best_index]\n\u001b[1;32m--> 126\u001b[0m best_model\u001b[38;5;241m=\u001b[39m\u001b[43mbest_trial\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresult\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    128\u001b[0m param_vals \u001b[38;5;241m=\u001b[39m best_trial[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmisc\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvals\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    129\u001b[0m flattened_params \u001b[38;5;241m=\u001b[39m {k: v[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m v \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m param_vals\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mKeyError\u001b[0m: 'model'"
     ]
    }
   ],
   "source": [
    "# pipeline \n",
    "try: \n",
    "    config=HyperOptParamsConfigManager()\n",
    "    hyperopt_config=config.get_hyperopt_config()\n",
    "    hyperopt_config_training=hyperOptTraining(config=hyperopt_config)\n",
    "    best_results,trails=hyperopt_config_training.train()\n",
    "    #hyperopt_config_training.register_best_model(best_results,trails)\n",
    "except Exception as e:\n",
    "    raise e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mhyperopt_config_training\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrails\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 126\u001b[0m, in \u001b[0;36mhyperOptTraining.register_best_model\u001b[1;34m(self, best_results, trials)\u001b[0m\n\u001b[0;32m    124\u001b[0m best_index\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmin([trial[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m trials\u001b[38;5;241m.\u001b[39mtrials])\n\u001b[0;32m    125\u001b[0m best_trial\u001b[38;5;241m=\u001b[39mtrials\u001b[38;5;241m.\u001b[39mtrials[best_index]\n\u001b[1;32m--> 126\u001b[0m best_model\u001b[38;5;241m=\u001b[39m\u001b[43mbest_trial\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresult\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    128\u001b[0m param_vals \u001b[38;5;241m=\u001b[39m best_trial[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmisc\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvals\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    129\u001b[0m flattened_params \u001b[38;5;241m=\u001b[39m {k: v[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m v \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m param_vals\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[1;31mKeyError\u001b[0m: 'model'"
     ]
    }
   ],
   "source": [
    "hyperopt_config_training.register_best_model(best_results,trails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
