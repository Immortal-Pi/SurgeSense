{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\pythonProjects\\\\SurgeSense\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\pythonProjects\\\\SurgeSense'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity \n",
    "import os \n",
    "from pathlib import Path \n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainConfig:\n",
    "    root_dir: Path \n",
    "    train_data_path: Path \n",
    "    test_data_path: Path \n",
    "    model_name: str \n",
    "    n_estimators: int \n",
    "    max_depth: int \n",
    "    min_samples_split: int \n",
    "    learning_rate: int\n",
    "    select_model: str\n",
    "    target_column: str \n",
    "    categorical_columns:list\n",
    "    numerical_columns:list\n",
    "    drop_columns:list \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config \n",
    "from SurgeSense.constants import * \n",
    "from SurgeSense.utils.common import read_yaml, create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath=CONFIG_FILE_PATH,\n",
    "            param_filepath=PARAMS_FILE_PATH,\n",
    "            schema_filepath=SCHEMA_FILE_PATH):\n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.param=read_yaml(param_filepath)\n",
    "        self.schema=read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_train_config(self)->ModelTrainConfig:\n",
    "        config=self.config.model_trainer\n",
    "        params=self.param.select_model \n",
    "        schema=self.schema\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_train_config=ModelTrainConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            n_estimators=params.n_estimators,\n",
    "            max_depth=params.max_depth,\n",
    "            min_samples_split=params.min_samples_split,\n",
    "            learning_rate=params.learning_rate,\n",
    "            select_model=params.algo,\n",
    "            target_column=schema.TARGET_COLUMN.name,\n",
    "            categorical_columns=schema.TRANSFORM.CATEGORICAL_DATA,\n",
    "            numerical_columns=schema.TRANSFORM.NUMERICAL_DATA,\n",
    "            drop_columns=schema.DROP_COLUMNS\n",
    "\n",
    "\n",
    "        )\n",
    "\n",
    "        return model_train_config\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# component \n",
    "import pandas as pd \n",
    "import os \n",
    "from SurgeSense import logger\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainConfig):\n",
    "        self.config=config\n",
    "\n",
    "    def create_pipeline(self):\n",
    "        \n",
    "        categorical_columns=self.config.categorical_columns\n",
    "        numerical_columns=self.config.numerical_columns\n",
    "\n",
    "        numerical_preprocessor=Pipeline(\n",
    "            steps=[\n",
    "                ('imputation_menu',SimpleImputer(missing_values=np.nan,strategy='median')),\n",
    "                ('scalar',StandardScaler())\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        categorical_preprocessor=Pipeline(\n",
    "            steps=[\n",
    "                ('imputation_constant',SimpleImputer(strategy='most_frequent')),\n",
    "                ('encode',OneHotEncoder(handle_unknown='ignore'))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        preprocessor=ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('categorical_columns',categorical_preprocessor,categorical_columns),\n",
    "                ('numerical_columns',numerical_preprocessor,numerical_columns)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if self.config.select_model=='XGBoostRegressor':\n",
    "            pipe=Pipeline(\n",
    "                steps=[\n",
    "                    ('preprocessor',preprocessor),\n",
    "                    ('model', XGBRegressor(\n",
    "                        n_estimators=self.config.n_estimators,\n",
    "                        learning_rate= self.config.learning_rate,\n",
    "                        max_depth=self.config.max_depth\n",
    "                    ))\n",
    "                ]\n",
    "            )\n",
    "        elif self.config.select_model=='GRADIENT_BOOSTING':\n",
    "            pipe=Pipeline(\n",
    "                steps=[\n",
    "                    ('preprocessor',preprocessor),\n",
    "                    ('model', GradientBoostingRegressor(\n",
    "                        n_estimators=self.config.n_estimators,\n",
    "                        learning_rate= self.config.learning_rate,\n",
    "                        max_depth=self.config.max_depth\n",
    "                    ))\n",
    "                ]\n",
    "            )\n",
    "        elif self.config.select_model=='RANDOM_FOREST':\n",
    "            pipe=Pipeline(\n",
    "                steps=[\n",
    "                    ('preprocessor',preprocessor),\n",
    "                    ('model', RandomForestRegressor(\n",
    "                        n_estimators=self.config.n_estimators,\n",
    "                        learning_rate= self.config.learning_rate,\n",
    "                        max_depth=self.config.max_depth\n",
    "                    ))\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return pipe\n",
    "\n",
    "    def train(self, pipe: Pipeline):\n",
    "        train_data=pd.read_csv(self.config.train_data_path)\n",
    "        test_data=pd.read_csv(self.config.test_data_path)\n",
    "\n",
    "        train_x=train_data.drop([self.config.target_column]+self.config.drop_columns,axis=1)\n",
    "        test_x=test_data.drop([self.config.target_column]+self.config.drop_columns,axis=1)\n",
    "        train_y=train_data[[self.config.target_column]]\n",
    "        test_y=test_data[[self.config.target_column]]\n",
    "        # print(test_x.columns)\n",
    "        pipe.fit(train_x,train_y)\n",
    "        joblib.dump(pipe,os.path.join(self.config.root_dir,self.config.model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-30 18:22:04,301: INFO :common : yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-03-30 18:22:04,306: INFO :common : yaml file: params.yaml loaded successfully]\n",
      "[2025-03-30 18:22:04,311: INFO :common : yaml file: schema.yaml loaded successfully]\n",
      "[2025-03-30 18:22:04,313: INFO :common : created directory at: artifacts]\n",
      "[2025-03-30 18:22:04,314: INFO :common : created directory at: artifacts/model_trainer]\n"
     ]
    }
   ],
   "source": [
    "# pipeline \n",
    "try:\n",
    "    config=ConfigurationManager()\n",
    "    model_trainer_config=config.get_model_train_config()\n",
    "    model_trainer=ModelTrainer(config=model_trainer_config)\n",
    "    pipeline=model_trainer.create_pipeline()\n",
    "    model_trainer.train(pipeline)\n",
    "except Exception as e:\n",
    "    raise e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-30 18:22:28,153: INFO :common : yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-03-30 18:22:28,159: INFO :common : yaml file: params.yaml loaded successfully]\n",
      "[2025-03-30 18:22:28,164: INFO :common : yaml file: schema.yaml loaded successfully]\n",
      "[2025-03-30 18:22:28,165: INFO :common : created directory at: artifacts]\n",
      "[2025-03-30 18:22:28,166: INFO :common : created directory at: artifacts/model_trainer]\n"
     ]
    }
   ],
   "source": [
    "config=ConfigurationManager()\n",
    "model_trainer_config=config.get_model_train_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=pd.read_csv(params.model_trainer.train_data_path)\n",
    "# data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
